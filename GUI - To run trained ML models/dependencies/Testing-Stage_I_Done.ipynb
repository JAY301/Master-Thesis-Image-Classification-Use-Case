{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install efficientnet_pytorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from collections import OrderedDict \n",
    "import shutil\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "#debug mode\n",
    "debug=True\n",
    "\n",
    "#loaded_model_path=os.path.normpath(sys.argv[0])\n",
    "\n",
    "loaded_model_path = os.getcwd()\n",
    "load_model=os.path.join(loaded_model_path,'checkpoint_stage_I.pth')\n",
    "\n",
    "csv_file_name=\"Classified_Images_stage_II.csv\"\n",
    "data_dir=r'dataset'\n",
    "\n",
    "batch_size = 100\n",
    "num_workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if debug==True:\n",
    "    if not train_on_gpu:\n",
    "        print('CUDA is not available.  Training on CPU ...')\n",
    "    else:\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already Exsists..\n"
     ]
    }
   ],
   "source": [
    "paths_of_files = []\n",
    "test_folder_path=os.path.join(os.path.join(data_dir,'Sorted_Images_I'),'test')\n",
    "#test_product_defect = r'dataset\\Sorted_Images_I\\Product Defect'\n",
    "\n",
    "if not os.path.exists(test_folder_path):\n",
    "    os.makedirs(test_folder_path)\n",
    "    \n",
    "    #make a directory in test/test with images to be sent into...\n",
    "    #get root, directory and files\n",
    "    for root, direc, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            paths_of_files.append(os.path.join(root, file))\n",
    "    \n",
    "    for i, f in enumerate(paths_of_files):\n",
    "        old_image_path=paths_of_files[i]\n",
    "        new_image_path =os.path.join(root, paths_of_files[i].split(os.sep)[-1])\n",
    "        shutil.copy(old_image_path, new_image_path) \n",
    "    \n",
    "    print (\" {:d} images moved  --> ../Sorted_Images_I\".format(len(paths_of_files)))\n",
    "else:\n",
    "    print('Already Exsists..')\n",
    "\t\n",
    "\n",
    "test_dir = os.path.join(data_dir, 'Sorted_Images_I')\n",
    "# classes are folders in each directory with these names\n",
    "classes = ['Lot Code', 'Other', 'Package', 'Product Defect', 'Receipt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "test_data = ImageFolderWithPaths(test_dir, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of DataParallel(\n",
      "  (module): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (16): ReLU(inplace=True)\n",
      "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (32): ReLU(inplace=True)\n",
      "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (35): ReLU(inplace=True)\n",
      "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (38): ReLU(inplace=True)\n",
      "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (42): ReLU(inplace=True)\n",
      "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (45): ReLU(inplace=True)\n",
      "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (48): ReLU(inplace=True)\n",
      "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (51): ReLU(inplace=True)\n",
      "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=8638, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=8638, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_checkpoint(load_model)\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Batch 0\n",
      "Analyzing Batch 1\n",
      "Analyzing Batch 2\n",
      "Analyzing Batch 3\n",
      "Analyzing Batch 4\n",
      "Analyzing Batch 5\n",
      "Analyzing Batch 6\n",
      "Analyzing Batch 7\n",
      "Analyzing Batch 8\n",
      "Analyzing Batch 9\n",
      "Analyzing Batch 10\n",
      "Analyzing Batch 11\n",
      "Analyzing Batch 12\n",
      "Analyzing Batch 13\n",
      "Analyzing Batch 14\n",
      "Analyzing Batch 15\n",
      "Analyzing Batch 16\n",
      "Analyzing Batch 17\n",
      "Analyzing Batch 18\n",
      "Analyzing Batch 19\n",
      "Analyzing Batch 20\n",
      "Analyzing Batch 21\n",
      "Analyzing Batch 22\n",
      "Analyzing Batch 23\n",
      "Analyzing Batch 24\n",
      "Analyzing Batch 25\n",
      "Analyzing Batch 26\n",
      "Analyzing Batch 27\n",
      "Analyzing Batch 28\n",
      "Analyzing Batch 29\n",
      "Analyzing Batch 30\n",
      "Analyzing Batch 31\n",
      "Analyzing Batch 32\n",
      "Analyzing Batch 33\n",
      "Analyzing Batch 34\n",
      "Analyzing Batch 35\n",
      "Analyzing Batch 36\n",
      "Analyzing Batch 37\n",
      "Analyzing Batch 38\n",
      "Analyzing Batch 39\n",
      "Analyzing Batch 40\n",
      "Analyzing Batch 41\n",
      "Analyzing Batch 42\n",
      "Analyzing Batch 43\n",
      "Analyzing Batch 44\n",
      "Analyzing Batch 45\n",
      "Analyzing Batch 46\n",
      "Analyzing Batch 47\n",
      "Analyzing Batch 48\n",
      "Analyzing Batch 49\n",
      "Analyzing Batch 50\n",
      "Analyzing Batch 51\n",
      "Analyzing Batch 52\n",
      "Analyzing Batch 53\n",
      "Time taken for Testing: 0:15:19.962843\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "total_preds=np.array([])\n",
    "total_labels=np.array([])\n",
    "\n",
    "# track test loss \n",
    "# over 5  classes\n",
    "test_loss = 0.0\n",
    "df = pd.DataFrame(columns=['Predicted Class','Path'])\n",
    "\n",
    "\n",
    "batch_number=0\n",
    "Start_time=(datetime.datetime.now())\n",
    "model.eval() # evaluation mode\n",
    "\n",
    "# iterate over test data\n",
    "for batch_number, (data, target, path) in enumerate(test_loader):\n",
    "    print(\"Analyzing Batch {}\".format(batch_number))\n",
    "    #create a sub dataframe    \n",
    "    sub_df = pd.DataFrame(columns=['Predicted Class','Path'])\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    #debug step --- print('The output:{}'.format(output.shape))\n",
    "    # calculate the batch loss\n",
    "    #loss = criterion(output, target)\n",
    "    \n",
    "    # update  test loss \n",
    "    # test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1) \n",
    "   \n",
    "\n",
    "   #%%     \n",
    "    ########################################################\n",
    "    ##############Write to a CSV File ######################\n",
    "    ########################################################    \n",
    "    \n",
    "   \n",
    "    for idx in np.arange(len(pred)): \n",
    "\n",
    "        #write to the CSV file\n",
    "        sub_df.loc[idx,'Predicted Class'] = classes[pred[idx]]\n",
    "        sub_df.loc[idx,'Path']= path[idx]\n",
    "    \n",
    "    #append sub_df to the main df\n",
    "    df=df.append(sub_df, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "End_time=(datetime.datetime.now())   \n",
    "\n",
    "print('Time taken for Testing: {}'.format(End_time-Start_time))\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicted Class                                               Path\n",
      "900  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001VEmm0UA...\n",
      "901        Lot Code  dataset\\Sorted_Images_I\\test\\00P2E00001R2tKhUA...\n",
      "902  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001cWlFNUA...\n",
      "903  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001VGQI2UA...\n",
      "904  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001ZaIoJUA...\n",
      "905  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001c1epRUA...\n",
      "906  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001XmIafUA...\n",
      "907  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001XmBz7UA...\n",
      "908  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001dHe6JUA...\n",
      "909  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001PqtkjUA...\n",
      "910  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001baWSNUA...\n",
      "911  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001echyzUA...\n",
      "912  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001SpPMyUA...\n",
      "913  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001R0xX9UA...\n",
      "914         Receipt  dataset\\Sorted_Images_I\\test\\00P2E00001UJ8VIUA...\n",
      "915        Lot Code  dataset\\Sorted_Images_I\\test\\00P8000001HcJ6qEA...\n",
      "916  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001ee7pVUA...\n",
      "917  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001gjQOgUA...\n",
      "918  Product Defect  dataset\\Sorted_Images_I\\test\\00P2E00001YGiXBUA...\n",
      "919        Lot Code  dataset\\Sorted_Images_I\\test\\00P2E00001RUEVmUA...\n"
     ]
    }
   ],
   "source": [
    "print(df[900:920])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676 of images were classified as Lot Code\n",
      "18 of images were classified as Other\n",
      "356 of images were classified as Package\n",
      "4268 of images were classified as Product Defect\n",
      "81 of images were classified as Receipt\n",
      "Total classified images: 5399 \n"
     ]
    }
   ],
   "source": [
    "for i, class_name in enumerate(classes):\n",
    "   #make 5 folders \n",
    "    new_path = os.path.join(test_dir, class_name)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path)\n",
    "    \n",
    "    print(\"{} of images were classified as {}\".format(  len(df[df['Predicted Class']==class_name]) ,class_name))\n",
    "\n",
    "print(\"Total classified images: {} \".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***All images are sorted & \"Classfied_Images.csv\" was generated***\n"
     ]
    }
   ],
   "source": [
    "for i,row in df.iterrows():\n",
    "    \n",
    "    old_path=df.loc[i,'Path']    \n",
    "    new_path=os.path.join(test_dir,df.loc[i,'Predicted Class'],df.loc[i,'Path'].split(os.sep)[-1])\n",
    "    shutil.move(old_path, new_path)\n",
    "    \n",
    "\n",
    "#saves the processed data to data.csv file\n",
    "df.to_csv(csv_file_name, sep='\\t',index=False,  encoding='latin-1') \n",
    "print('***All images are sorted & \"Classfied_Images.csv\" was generated***')\n",
    "\n",
    "#delete folder dataset\\images\\Sorted_Images_I\\test\n",
    "if not Path(test_folder_path).is_file():\n",
    "    os.rmdir(test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
