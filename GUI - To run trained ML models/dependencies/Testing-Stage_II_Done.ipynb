{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "import datetime\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from collections import OrderedDict \n",
    "import shutil\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "\n",
    "#debug mode\n",
    "debug=True\n",
    "\n",
    "#loaded_model_path=os.path.normpath(sys.argv[0])\n",
    "\n",
    "loaded_model_path = os.getcwd()\n",
    "load_model=os.path.join(loaded_model_path,'checkpoint_stage_II.pth')\n",
    "\n",
    "csv_file_name=\"Classified_Images_stage_III.csv\"\n",
    "data_dir=r'dataset'\n",
    "\n",
    "batch_size = 100\n",
    "num_workers=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends\n",
    "    torchvision.datasets.ImageFolder\n",
    "    \"\"\"\n",
    "\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if debug==True:\n",
    "    if not train_on_gpu:\n",
    "        print('CUDA is not available.  Training on CPU ...')\n",
    "    else:\n",
    "        print('CUDA is available!  Training on GPU ...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_of_files = []\n",
    "test_folder_path=os.path.join(os.path.join(data_dir,'Sorted_Images_I'),'Product Defect')\n",
    "test_folder_path1=os.path.join(os.path.join(data_dir,'Sorted_Images_I'),'Product Defect\\Product Defect')\n",
    "#test_product_defect = r'dataset\\Sorted_Images_I\\Product Defect'\n",
    "\n",
    "\n",
    "if not os.path.exists(test_folder_path1):\n",
    "    os.makedirs(test_folder_path1)\n",
    "    \n",
    "    #make a directory in test/test with images to be sent into...\n",
    "    #get root, directory and files\n",
    "for root, direc, files in os.walk(test_folder_path):\n",
    "    for file in files:\n",
    "        paths_of_files.append(os.path.join(root, file))\n",
    "    \n",
    "for i, f in enumerate(paths_of_files):\n",
    "    old_image_path=paths_of_files[i]\n",
    "    #new_image_path =os.path.join(root, paths_of_files[i].split(os.sep)[-1])\n",
    "    shutil.copy(old_image_path, test_folder_path1) \n",
    "    \n",
    "print (\" {:d} images moved  --> ../Sorted_Images_I\".format(len(paths_of_files)))\n",
    "#else:\n",
    "    #print('Already Exsists..')\n",
    "\t\n",
    "\n",
    "#test_dir = os.path.join(data_dir, 'Sorted_Images_I')\n",
    "# classes are folders in each directory with these names\n",
    "#classes = ['Lot Code', 'Other', 'Package', 'Product Defect', 'Receipt']\n",
    "classes = ['Other', 'back ear tearing', 'front ear tearing', 'tape tearing']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Other', 'back ear tearing', 'front ear tearing', 'tape tearing']\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "test_data = ImageFolderWithPaths(test_folder_path, transform=test_transforms)\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_checkpoint(load_model)\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_preds=np.array([])\n",
    "total_labels=np.array([])\n",
    "\n",
    "# track test loss \n",
    "# over 5  classes\n",
    "test_loss = 0.0\n",
    "df = pd.DataFrame(columns=['Predicted Class','Path'])\n",
    "\n",
    "\n",
    "batch_number=0\n",
    "Start_time=(datetime.datetime.now())\n",
    "#model.eval() # evaluation mode\n",
    "\n",
    "# iterate over test data\n",
    "for batch_number, (data, target, path) in enumerate(test_loader):\n",
    "    print(\"Analyzing Batch {}\".format(batch_number))\n",
    "    #create a sub dataframe    \n",
    "    sub_df = pd.DataFrame(columns=['Predicted Class','Path'])\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    #debug step --- print('The output:{}'.format(output.shape))\n",
    "    # calculate the batch loss\n",
    "    #loss = criterion(output, target)\n",
    "    \n",
    "    # update  test loss \n",
    "    # test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1) \n",
    "   \n",
    "\n",
    "   #%%     \n",
    "    ########################################################\n",
    "    ##############Write to a CSV File ######################\n",
    "    ########################################################    \n",
    "    \n",
    "   \n",
    "    for idx in np.arange(len(pred)): \n",
    "\n",
    "        #write to the CSV file\n",
    "        sub_df.loc[idx,'Predicted Class'] = classes[pred[idx]]\n",
    "        sub_df.loc[idx,'Path']= path[idx]\n",
    "    \n",
    "    #append sub_df to the main df\n",
    "    df=df.append(sub_df, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "End_time=(datetime.datetime.now())   \n",
    "\n",
    "print('Time taken for Testing: {}'.format(End_time-Start_time))\n",
    "print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[1600:1620])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, class_name in enumerate(classes):\n",
    "   #make 5 folders \n",
    "    new_path = os.path.join(test_folder_path, class_name)\n",
    "    if not os.path.exists(new_path):\n",
    "        os.makedirs(new_path)\n",
    "    \n",
    "    print(\"{} of images were classified as {}\".format(  len(df[df['Predicted Class']==class_name]) ,class_name))\n",
    "\n",
    "print(\"Total classified images: {} \".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in df.iterrows():\n",
    "    \n",
    "    old_path=df.loc[i,'Path']    \n",
    "    new_path=os.path.join(test_folder_path,df.loc[i,'Predicted Class'],df.loc[i,'Path'].split(os.sep)[-1])\n",
    "    shutil.move(old_path, new_path)\n",
    "    \n",
    "\n",
    "#saves the processed data to data.csv file\n",
    "df.to_csv(csv_file_name, sep='\\t',index=False,  encoding='latin-1') \n",
    "print('***All images are sorted & \"Classfied_Images.csv\" was generated***')\n",
    "\n",
    "#delete folder dataset\\images\\Sorted_Images_I\\test\n",
    "#if not Path(test_folder_path).is_file():\n",
    "    #os.rmdir(test_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
